# 빅데이터 처리 클러스터 구축(단일 노드)

## EC2

- 운영체제: ubuntu 24.04 LTS
- 인스턴스 타입: t2.xlarge
- 스토리지: 20GiB

## 버전 정보

- openjdk ver 1.8.0
- python 3.8.2
- Apache Hadoop 3.2.3
- Apache Spark 3.2.1
- Apache Zookeeper 3.8.0
- Zeppelin 0.10.1

## 클러스터 구축 방법

### 1. AWS EC2 인스턴스 배포 및 연결(MobaXterm활용)

- 인스턴스 배포
- 인스턴스 연결

### 2. Java 설치 및 환경설정

- hadoop, yarn, spark, zookeeper는 자바와 스칼라로 개발되었으며, 실행을 위해 JVM이 필요.

### 3. Hadoop 설치 및 환경설정

### 4. Spark 설치 및 환경설정

### 5. Zookeeper 설치 및 환경설정

- SSH 키 설정

### 6. AMI 생성 및 인스턴스 복제

### 7. 탄력적IP 및 호스트이름 설정

- 로컬에서 각 인스턴스 접근 설정(단일노드라 nn1 하나만 설정)

### 8. Zookeeper 클러스터 실행

### 9. Hadoop 클러스터 실행

- Yarn 실행
- 잡 히스토리 서버 실행
- 맵리듀스 동작 테스트(워드카운트)

### 10. Spark 클러스터 실행

### 11. 보안그룹 편집 및 WebUI 확인

- 하둡 WEB UI 접속 (http://<nn1 public IP>:50070)
- 얀 WEB UI 접속(http://<nn1 public IP>:8088)
- 7. 스파크 WEB UI 접속(http://<nn1 public IP>:18080)

### 12. 클러스터 실행 스크립트 생성 및 권한설정

- 클러스터 실행 스크립트 생성
- 스크립트 권한 설정

### 13. Zeppelin 설치 및 PySpark 연동

- 스파크를 다룰 때 분석하기 쉽고, 인터프리터 환경에서 데이터를 분석할 수 있는 제플린 환경을 설치
- 제플린 config파일 설정
- 제플린 실행
- 제플린 보안그룹 설정

## 구축 후기

https://www.notion.so/19e7e8c32574803d983ad111f7cea27b
코치 세션을 통해 코치님께서 주신 노션을 잘 활용할 수 있음에 감사하다.
우리 프로젝트에서는 여행 소비패턴을 분석할 때 사용할 것이라서 t2.xlarge 인스턴스 하나로만 가능할 것 같다는 판단하에
단일 노드로 구축하였다. 후에 부족하다면 하나 더 추가해서 워커노드로 사용할 예정이다. (돈 쓰기 싫은거 아님)
이틀동안 각 필요한 부분 설치하고 환경설정하는 것에 막히는 부분도 많아 권한설정을 바꾸고 그대로 설치한 부분도 많았다.
지금은 실행만 되는 것을 확인했는데 내일부터 AI HUB에서 데이터를 가지고 파이프라인을 구현하는 과정에서 잘못된 설정이 없길 바란다....
