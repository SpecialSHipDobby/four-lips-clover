# Resilient Distributed Dataset (RDD)

## RDD란?

🔹 RDD(Resilient Distributed Dataset)는 Apache Spark의 **핵심 데이터 구조**입니다.

🔹 불변성(immutable)을 가진 분산 객체 컬렉션으로, 클러스터 전체에 걸쳐 병렬 처리가 가능합니다.

🔹 **내결함성**(fault tolerance)을 제공하며, Spark의 분산 컴퓨팅 기능의 기반이 됩니다.

## RDD의 핵심 특성

### 1️⃣ 불변성 (Immutability)

- 한 번 생성된 RDD는 수정할 수 없습니다.
- RDD에 변환 작업을 수행하면 새로운 RDD가 생성됩니다.

### 2️⃣ 분산 처리 (Distributed)

- RDD 데이터는 클러스터의 여러 노드에 분산되어 저장됩니다.
- 이를 통해 대규모 데이터에 대한 효율적인 병렬 처리가 가능합니다.

### 3️⃣ 복원력 (Resilience/Fault Tolerance)

- RDD는 계보 정보(lineage)를 사용하여 손실된 데이터를 자동으로 복구합니다.
- 계보 정보는 RDD가 다른 RDD로부터 어떻게 파생되었는지에 대한 기록입니다.

### 4️⃣ 지연 평가 (Lazy Evaluation)

- RDD의 변환 작업은 즉시 실행되지 않습니다.
- 대신, 계보로 기록되며 실제 계산은 액션(collect(), save() 등)이 호출될 때만 발생합니다.
- 이 방식으로 Spark는 효율적인 실행 계획을 수립할 수 있습니다.

### 5️⃣ 파티셔닝 (Partitioned)

- RDD는 논리적 파티션으로 나뉘어 다양한 클러스터 노드에서 병렬 처리됩니다.
- 파티셔닝은 데이터 지역성과 처리 효율성을 높이는 데 중요한 역할을 합니다.

## RDD의 장점

### 📊 확장성

- 대용량 데이터셋 처리에 적합한 수평적 확장 가능
- 수천 개의 노드에 걸쳐 페타바이트 단위의 데이터 처리 가능

### 🔄 유연성

- 다양한 데이터 소스(텍스트 파일, 하둡 파일, 데이터베이스 등)로부터 RDD 생성 가능
- 광범위한 변환 및 액션 연산자 지원

### 🛡️ 내결함성

- 노드 장애 발생 시에도 데이터 손실 없이 작업 계속 가능
- 계보 정보를 통해 손실된 파티션 자동 재구성

### ⚡ 성능

- 인메모리 처리로 반복적인 연산 속도 향상
- 지연 평가를 통한 최적화된 실행 계획

## RDD 작업 유형

### 1️⃣ 변환 (Transformations)

- 기존 RDD에서 새로운 RDD를 생성하는 작업
- 예: map(), filter(), flatMap(), groupByKey()
- 지연 평가 방식으로 실행됨

### 2️⃣ 액션 (Actions)

- RDD에서 실제 결과값을 반환하거나 저장하는 작업
- 예: collect(), count(), save(), reduce()
- 실제 계산 작업 트리거

## Spark에서 RDD 사용 예시 (Python)

```python
# RDD 생성
rdd = sc.parallelize([1, 2, 3, 4, 5])

# 변환 작업 (새 RDD 생성)
squared_rdd = rdd.map(lambda x: x * x)

# 액션 작업 (실제 계산 실행)
result = squared_rdd.collect()  # [1, 4, 9, 16, 25]

```

## RDD vs DataFrame vs DataSet

RDD는 Spark의 가장 기본적인 데이터 추상화이지만, 최신 Spark 버전에서는 더 높은 수준의 추상화인 DataFrame과 DataSet을 주로 사용합니다:

- **RDD**: 저수준 API, 완전한 유연성, 타입 안전성
- **DataFrame**: 구조화된 데이터를 위한 중간 수준 API, 최적화 기회 제공
- **DataSet**: 강력한 타입 안전성과 함께 최적화된 실행 계획 제공 (주로 Scala, Java)

하지만 RDD는 여전히 Spark의 기반이 되는 중요한 개념으로, 모든 상위 수준 추상화는 내부적으로 RDD 작업으로 변환됩니다.
